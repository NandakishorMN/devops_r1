{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1889219,"sourceType":"datasetVersion","datasetId":1125482}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:23:27.945252Z","iopub.execute_input":"2025-09-03T16:23:27.945593Z","iopub.status.idle":"2025-09-03T16:23:27.960602Z","shell.execute_reply.started":"2025-09-03T16:23:27.945568Z","shell.execute_reply":"2025-09-03T16:23:27.959817Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/gemstone-price-prediction/cubic_zirconia.csv\n/kaggle/input/gemstone-price-prediction/Data Dictionary.xlsx\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfile_path = r'/kaggle/input/gemstone-price-prediction/cubic_zirconia.csv'\n\ntry:\n    df = pd.read_csv(file_path)\n    print(\"First 5 rows of the dataset:\")\n    print(df.head())\n    print(\"\\n\")\n\nexcept FileNotFoundError:\n    print(f\"Error: The file was not found at {file_path}. Please check the path and try again.\")\n    print(\"Make sure you have added the 'cubic_zirconia.csv' dataset to your notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:23:27.962196Z","iopub.execute_input":"2025-09-03T16:23:27.962571Z","iopub.status.idle":"2025-09-03T16:23:28.026200Z","shell.execute_reply.started":"2025-09-03T16:23:27.962548Z","shell.execute_reply":"2025-09-03T16:23:28.025248Z"}},"outputs":[{"name":"stdout","text":"First 5 rows of the dataset:\n   Unnamed: 0  carat        cut color clarity  depth  table     x     y     z  \\\n0           1   0.30      Ideal     E     SI1   62.1   58.0  4.27  4.29  2.66   \n1           2   0.33    Premium     G      IF   60.8   58.0  4.42  4.46  2.70   \n2           3   0.90  Very Good     E    VVS2   62.2   60.0  6.04  6.12  3.78   \n3           4   0.42      Ideal     F     VS1   61.6   56.0  4.82  4.80  2.96   \n4           5   0.31      Ideal     F    VVS1   60.4   59.0  4.35  4.43  2.65   \n\n   price  \n0    499  \n1    984  \n2   6289  \n3   1082  \n4    779  \n\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 2. Handle Missing Values and Categorical Features\n\n# First, remove any rows that contain missing values (NaN).\n# This is a critical step because most models cannot handle NaN values.\ndf_clean = df.dropna()\n\n# Now, handle Categorical Features using One-Hot Encoding.\n# This will create new binary (0 or 1) columns for each category.\ndf_encoded = pd.get_dummies(df_clean, columns=['cut', 'color', 'clarity'], drop_first=True)\n\n# Drop the first column as it is an unnamed index column from the original data\n# and it is no longer needed after cleaning.\ndf_encoded = df_encoded.iloc[:, 1:]\n\n# Display the columns of the new encoded dataframe\nprint(\"Columns after cleaning and One-Hot Encoding:\")\nprint(df_encoded.columns)\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:23:28.027119Z","iopub.execute_input":"2025-09-03T16:23:28.027414Z","iopub.status.idle":"2025-09-03T16:23:28.054792Z","shell.execute_reply.started":"2025-09-03T16:23:28.027382Z","shell.execute_reply":"2025-09-03T16:23:28.053884Z"}},"outputs":[{"name":"stdout","text":"Columns after cleaning and One-Hot Encoding:\nIndex(['carat', 'depth', 'table', 'x', 'y', 'z', 'price', 'cut_Good',\n       'cut_Ideal', 'cut_Premium', 'cut_Very Good', 'color_E', 'color_F',\n       'color_G', 'color_H', 'color_I', 'color_J', 'clarity_IF', 'clarity_SI1',\n       'clarity_SI2', 'clarity_VS1', 'clarity_VS2', 'clarity_VVS1',\n       'clarity_VVS2'],\n      dtype='object')\n\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# 3. Define Features (X) and Target (y)\n# The target variable is 'price'\ny = df_encoded['price']\n\n# The features are all the other columns\nX = df_encoded.drop('price', axis=1)\n\nprint(\"Shape of Features (X):\", X.shape)\nprint(\"Shape of Target (y):\", y.shape)\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:23:28.056655Z","iopub.execute_input":"2025-09-03T16:23:28.057003Z","iopub.status.idle":"2025-09-03T16:23:28.065883Z","shell.execute_reply.started":"2025-09-03T16:23:28.056979Z","shell.execute_reply":"2025-09-03T16:23:28.064921Z"}},"outputs":[{"name":"stdout","text":"Shape of Features (X): (26270, 23)\nShape of Target (y): (26270,)\n\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# 4. Split data into training and testing sets\n# We'll use 80% for training and 20% for testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 5. Create and train the Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\nprint(\"Linear Regression model has been trained.\")\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:23:28.067077Z","iopub.execute_input":"2025-09-03T16:23:28.067447Z","iopub.status.idle":"2025-09-03T16:23:28.236696Z","shell.execute_reply.started":"2025-09-03T16:23:28.067415Z","shell.execute_reply":"2025-09-03T16:23:28.235912Z"}},"outputs":[{"name":"stdout","text":"Linear Regression model has been trained.\n\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# 6. Make predictions on the test set\npredictions = model.predict(X_test)\n\n# 7. Evaluate the model's performance\nmae = mean_absolute_error(y_test, predictions)\nmse = mean_squared_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\n\nprint(\"Model Evaluation:\")\nprint(f\"Mean Absolute Error (MAE): {mae:.2f}\")\nprint(f\"Mean Squared Error (MSE): {mse:.2f}\")\nprint(f\"R-squared (R²): {r2:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:23:55.434274Z","iopub.execute_input":"2025-09-03T16:23:55.434593Z","iopub.status.idle":"2025-09-03T16:23:55.450904Z","shell.execute_reply.started":"2025-09-03T16:23:55.434572Z","shell.execute_reply":"2025-09-03T16:23:55.449834Z"}},"outputs":[{"name":"stdout","text":"Model Evaluation:\nMean Absolute Error (MAE): 745.62\nMean Squared Error (MSE): 1984731.23\nR-squared (R²): 0.87\n","output_type":"stream"}],"execution_count":15}]}